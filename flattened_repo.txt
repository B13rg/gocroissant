<cmd/gocroissant/main.go>
// main.go
package main

import (
	"fmt"
	"os"
	"path/filepath"
	"strings"

	"github.com/beyondcivic/gocroissant/pkg/croissant"
	"github.com/beyondcivic/gocroissant/pkg/version"
	"github.com/spf13/cobra"
	"github.com/spf13/viper"
)

func main() {
	// Initialize viper for configuration
	viper.SetEnvPrefix("CROISSANT")
	viper.AutomaticEnv()

	var rootCmd = &cobra.Command{
		Use:   "gocroissant",
		Short: "Croissant metadata tools",
		Long: `A Go implementation for working with the ML Commons Croissant metadata format.
Croissant is a standardized way to describe machine learning datasets using JSON-LD.`,
		Version: version.Version,
	}

	// Version command
	var versionCmd = &cobra.Command{
		Use:   "version",
		Short: "Print the version information",
		Long:  `Print the version, git hash, and build time information of the gocroissant tool.`,
		Run: func(cmd *cobra.Command, args []string) {
			fmt.Printf("%s version %s\n", version.AppName, version.Version)
			fmt.Printf("Git commit: %s\n", version.GitHash)
			fmt.Printf("Built on: %s\n", version.BuildTime)
		},
	}
	rootCmd.AddCommand(versionCmd)

	// Generate command
	var generateCmd = &cobra.Command{
		Use:   "generate [csvPath]",
		Short: "Generate Croissant metadata from a CSV file",
		Long: `Generate Croissant metadata from a CSV file, automatically inferring data types 
and creating a structured JSON-LD output that complies with the ML Commons Croissant specification.`,
		Args: cobra.ExactArgs(1),
		Run: func(cmd *cobra.Command, args []string) {
			csvPath := args[0]
			outputPath, _ := cmd.Flags().GetString("output")
			validate, _ := cmd.Flags().GetBool("validate")
			strict, _ := cmd.Flags().GetBool("strict")
			checkFiles, _ := cmd.Flags().GetBool("check-files")

			// Validate input file
			if !fileExists(csvPath) {
				fmt.Printf("Error: CSV file '%s' does not exist.\n", csvPath)
				os.Exit(1)
			}

			if !isCSVFile(csvPath) {
				fmt.Printf("Error: File '%s' does not appear to be a CSV file.\n", csvPath)
				os.Exit(1)
			}

			// Determine output path
			outputPath = determineOutputPath(outputPath, csvPath)

			// Validate output path
			if err := croissant.ValidateOutputPath(outputPath); err != nil {
				fmt.Printf("Error: Invalid output path: %v\n", err)
				os.Exit(1)
			}

			// Generate metadata
			fmt.Printf("Generating Croissant metadata for '%s'...\n", csvPath)
			metadata, err := croissant.GenerateMetadataWithValidation(csvPath, outputPath)
			if err != nil {
				fmt.Printf("Error generating metadata: %v\n", err)
				os.Exit(1)
			}

			// Set validation options
			if validate || strict || checkFiles {
				options := croissant.DefaultValidationOptions()
				options.StrictMode = strict
				options.CheckFileExists = checkFiles
				metadata.ValidateWithOptions(options)

				report := metadata.Report()
				if report != "" {
					fmt.Println(report)
				} else {
					fmt.Println("✓ Validation passed with no issues.")
				}

				if metadata.HasErrors() {
					fmt.Printf("\nMetadata generation completed but with validation errors.\n")
					if outputPath != "" {
						fmt.Printf("Metadata saved to: %s\n", outputPath)
					}
					os.Exit(1)
				}
			}

			fmt.Printf("✓ Croissant metadata generated successfully")
			if outputPath != "" {
				fmt.Printf(" and saved to: %s\n", outputPath)
			} else {
				fmt.Println()
			}
		},
	}
	generateCmd.Flags().StringP("output", "o", "", "Output path for the metadata JSON file")
	generateCmd.Flags().BoolP("validate", "v", false, "Validate the generated metadata and print issues")
	generateCmd.Flags().Bool("strict", false, "Enable strict validation mode")
	generateCmd.Flags().Bool("check-files", false, "Check if referenced files exist")
	rootCmd.AddCommand(generateCmd)

	// Validate command
	var validateCmd = &cobra.Command{
		Use:   "validate [jsonldPath]",
		Short: "Validate an existing Croissant metadata file",
		Long: `Validate an existing Croissant metadata JSON-LD file and report any issues found.
This command checks compliance with the ML Commons Croissant specification.`,
		Args: cobra.ExactArgs(1),
		Run: func(cmd *cobra.Command, args []string) {
			jsonldPath := args[0]
			strict, _ := cmd.Flags().GetBool("strict")
			checkFiles, _ := cmd.Flags().GetBool("check-files")
			checkUrls, _ := cmd.Flags().GetBool("check-urls")

			// Validate input file
			if !fileExists(jsonldPath) {
				fmt.Printf("Error: Metadata file '%s' does not exist.\n", jsonldPath)
				os.Exit(1)
			}

			// Set validation options
			options := croissant.DefaultValidationOptions()
			options.StrictMode = strict
			options.CheckFileExists = checkFiles
			options.ValidateURLs = checkUrls

			fmt.Printf("Validating Croissant metadata file '%s'...\n", jsonldPath)

			// Read and parse the file manually to use validation options
			data, err := os.ReadFile(jsonldPath)
			if err != nil {
				fmt.Printf("Error reading file: %v\n", err)
				os.Exit(1)
			}

			issues, err := croissant.ValidateJSONWithOptions(data, options)
			if err != nil {
				fmt.Printf("Error validating metadata: %v\n", err)
				os.Exit(1)
			}

			report := issues.Report()
			if report != "" {
				fmt.Println(report)
			} else {
				fmt.Println("✓ Validation passed with no issues.")
			}

			if issues.HasErrors() {
				os.Exit(1)
			}
		},
	}
	validateCmd.Flags().Bool("strict", false, "Enable strict validation mode")
	validateCmd.Flags().Bool("check-files", false, "Check if referenced files exist")
	validateCmd.Flags().Bool("check-urls", false, "Validate URLs by making HTTP requests")
	rootCmd.AddCommand(validateCmd)

	// Info command - analyze CSV files
	var infoCmd = &cobra.Command{
		Use:   "info [csvPath]",
		Short: "Display information about a CSV file",
		Long:  `Analyze a CSV file and display information about its structure, columns, and data types.`,
		Args:  cobra.ExactArgs(1),
		Run: func(cmd *cobra.Command, args []string) {
			csvPath := args[0]
			sampleSize, _ := cmd.Flags().GetInt("sample-size")

			if !fileExists(csvPath) {
				fmt.Printf("Error: CSV file '%s' does not exist.\n", csvPath)
				os.Exit(1)
			}

			// Validate CSV structure
			if err := croissant.ValidateCSVStructure(csvPath); err != nil {
				fmt.Printf("CSV validation error: %v\n", err)
				os.Exit(1)
			}

			// Get file stats
			stats, err := croissant.GetFileStats(csvPath)
			if err != nil {
				fmt.Printf("Error getting file stats: %v\n", err)
				os.Exit(1)
			}

			// Count total rows
			totalRows, err := croissant.CountCSVRows(csvPath)
			if err != nil {
				fmt.Printf("Error counting rows: %v\n", err)
				os.Exit(1)
			}

			// Get column information with enhanced type detection
			headers, columnTypes, err := croissant.GetCSVColumnTypes(csvPath, sampleSize)
			if err != nil {
				fmt.Printf("Error analyzing CSV: %v\n", err)
				os.Exit(1)
			}

			// Display information
			fmt.Printf("CSV File Information: %s\n", csvPath)
			fmt.Printf("=====================================\n")
			fmt.Printf("File Size: %v bytes\n", stats["size"])
			fmt.Printf("Total Rows: %d (including header)\n", totalRows)
			fmt.Printf("Data Rows: %d\n", totalRows-1)
			fmt.Printf("Columns: %d\n", len(headers))
			fmt.Printf("Sample Size: %d rows\n", sampleSize)
			fmt.Println()

			fmt.Printf("Column Information:\n")
			fmt.Printf("-------------------\n")
			for i, header := range headers {
				fmt.Printf("%d. %s (%s)\n", i+1, header, columnTypes[i])
			}
		},
	}
	infoCmd.Flags().Int("sample-size", 10, "Number of rows to sample for type inference")
	rootCmd.AddCommand(infoCmd)

	// Execute the command
	if err := rootCmd.Execute(); err != nil {
		fmt.Println(err)
		os.Exit(1)
	}
}

// Helper functions

func fileExists(filename string) bool {
	info, err := os.Stat(filename)
	if os.IsNotExist(err) {
		return false
	}
	return !info.IsDir()
}

func isCSVFile(filename string) bool {
	return croissant.IsCSVFile(filename)
}

func determineOutputPath(providedPath, csvPath string) string {
	if providedPath != "" {
		return providedPath
	}

	// Check environment variable
	envOutputPath := os.Getenv("CROISSANT_OUTPUT_PATH")
	if envOutputPath != "" {
		return envOutputPath
	}

	// Generate default path based on CSV filename
	baseName := strings.TrimSuffix(filepath.Base(csvPath), filepath.Ext(csvPath))
	return baseName + "_metadata.jsonld"
}

</cmd/gocroissant/main.go>

<pkg/croissant/utils.go>
// utils.go
package croissant

import (
	"crypto/sha256"
	"encoding/csv"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
)

// CalculateSHA256 calculates the SHA-256 hash of a file
func CalculateSHA256(filePath string) (string, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return "", fmt.Errorf("failed to open file: %w", err)
	}
	defer file.Close()

	hash := sha256.New()
	if _, err := io.Copy(hash, file); err != nil {
		return "", fmt.Errorf("failed to calculate hash: %w", err)
	}

	return fmt.Sprintf("%x", hash.Sum(nil)), nil
}

// GetCSVColumns reads the column names and first row from a CSV file
func GetCSVColumns(csvPath string) ([]string, []string, error) {
	file, err := os.Open(csvPath)
	if err != nil {
		return nil, nil, fmt.Errorf("failed to open CSV file: %w", err)
	}
	defer file.Close()

	reader := csv.NewReader(file)
	reader.TrimLeadingSpace = true

	// Read headers
	headers, err := reader.Read()
	if err != nil {
		return nil, nil, fmt.Errorf("failed to read CSV headers: %w", err)
	}

	// Clean headers
	for i, header := range headers {
		headers[i] = strings.TrimSpace(header)
	}

	// Read first row for data type inference
	firstRow, err := reader.Read()
	if err != nil && err != io.EOF {
		return nil, nil, fmt.Errorf("failed to read first CSV row: %w", err)
	}

	// If we hit EOF, there's no data row
	if err == io.EOF {
		return headers, nil, nil
	}

	return headers, firstRow, nil
}

// GetCSVColumnsAndSampleRows reads column names and multiple sample rows for better type inference
func GetCSVColumnsAndSampleRows(csvPath string, maxRows int) ([]string, [][]string, error) {
	file, err := os.Open(csvPath)
	if err != nil {
		return nil, nil, fmt.Errorf("failed to open CSV file: %w", err)
	}
	defer file.Close()

	reader := csv.NewReader(file)
	reader.TrimLeadingSpace = true

	// Handle common CSV format issues
	reader.LazyQuotes = true
	reader.FieldsPerRecord = -1 // Allow variable number of fields

	// Read headers
	headers, err := reader.Read()
	if err != nil {
		return nil, nil, fmt.Errorf("failed to read CSV headers: %w", err)
	}

	// Clean headers
	for i, header := range headers {
		headers[i] = strings.TrimSpace(header)
	}

	// Read sample rows
	var sampleRows [][]string
	rowCount := 0

	for rowCount < maxRows {
		row, err := reader.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			return nil, nil, fmt.Errorf("failed to read CSV row %d: %w", rowCount+1, err)
		}

		sampleRows = append(sampleRows, row)
		rowCount++
	}

	return headers, sampleRows, nil
}

// ValidateOutputPath validates if the given path is a valid file path
func ValidateOutputPath(outputPath string) error {
	if outputPath == "" {
		return fmt.Errorf("output path cannot be empty")
	}

	// Check if the directory exists or can be created
	dir := filepath.Dir(outputPath)
	if dir != "." && dir != "" {
		if err := os.MkdirAll(dir, 0755); err != nil {
			return fmt.Errorf("cannot create directory %s: %v", dir, err)
		}
	}

	// Check if we can write to the file (create a temporary file to test)
	tempFile := outputPath + ".tmp"
	file, err := os.Create(tempFile)
	if err != nil {
		return fmt.Errorf("cannot write to path %s: %v", outputPath, err)
	}
	file.Close()
	os.Remove(tempFile) // Clean up the temporary file

	return nil
}

// DetectCSVDelimiter attempts to detect the CSV delimiter
func DetectCSVDelimiter(csvPath string) (rune, error) {
	file, err := os.Open(csvPath)
	if err != nil {
		return ',', fmt.Errorf("failed to open CSV file: %w", err)
	}
	defer file.Close()

	// Read first few lines to detect delimiter
	buffer := make([]byte, 1024)
	n, err := file.Read(buffer)
	if err != nil && err != io.EOF {
		return ',', fmt.Errorf("failed to read file sample: %w", err)
	}

	sample := string(buffer[:n])

	// Count occurrences of common delimiters
	delimiters := map[rune]int{
		',':  strings.Count(sample, ","),
		';':  strings.Count(sample, ";"),
		'\t': strings.Count(sample, "\t"),
		'|':  strings.Count(sample, "|"),
	}

	// Find the most common delimiter
	maxCount := 0
	bestDelimiter := ','
	for delimiter, count := range delimiters {
		if count > maxCount {
			maxCount = count
			bestDelimiter = delimiter
		}
	}

	return bestDelimiter, nil
}

// ParseCSVWithOptions parses a CSV file with custom options
func ParseCSVWithOptions(csvPath string, delimiter rune, hasHeader bool) ([]string, [][]string, error) {
	file, err := os.Open(csvPath)
	if err != nil {
		return nil, nil, fmt.Errorf("failed to open CSV file: %w", err)
	}
	defer file.Close()

	reader := csv.NewReader(file)
	reader.Comma = delimiter
	reader.TrimLeadingSpace = true
	reader.LazyQuotes = true
	reader.FieldsPerRecord = -1

	var headers []string
	var rows [][]string

	// Read all records
	records, err := reader.ReadAll()
	if err != nil {
		return nil, nil, fmt.Errorf("failed to read CSV records: %w", err)
	}

	if len(records) == 0 {
		return nil, nil, fmt.Errorf("CSV file is empty")
	}

	if hasHeader {
		headers = records[0]
		rows = records[1:]
	} else {
		// Generate default headers
		if len(records) > 0 {
			for i := 0; i < len(records[0]); i++ {
				headers = append(headers, fmt.Sprintf("column_%d", i+1))
			}
		}
		rows = records
	}

	// Clean headers
	for i, header := range headers {
		headers[i] = strings.TrimSpace(header)
		if headers[i] == "" {
			headers[i] = fmt.Sprintf("column_%d", i+1)
		}
	}

	return headers, rows, nil
}

// GetFileStats returns basic statistics about a file
func GetFileStats(filePath string) (map[string]interface{}, error) {
	fileInfo, err := os.Stat(filePath)
	if err != nil {
		return nil, fmt.Errorf("failed to get file stats: %w", err)
	}

	stats := map[string]interface{}{
		"name":      fileInfo.Name(),
		"size":      fileInfo.Size(),
		"mode":      fileInfo.Mode(),
		"modTime":   fileInfo.ModTime(),
		"isDir":     fileInfo.IsDir(),
		"extension": filepath.Ext(filePath),
		"basename":  strings.TrimSuffix(fileInfo.Name(), filepath.Ext(fileInfo.Name())),
	}

	return stats, nil
}

// CountCSVRows counts the total number of rows in a CSV file (including header)
func CountCSVRows(csvPath string) (int, error) {
	file, err := os.Open(csvPath)
	if err != nil {
		return 0, fmt.Errorf("failed to open CSV file: %w", err)
	}
	defer file.Close()

	reader := csv.NewReader(file)
	reader.LazyQuotes = true
	reader.FieldsPerRecord = -1

	rowCount := 0
	for {
		_, err := reader.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			return 0, fmt.Errorf("failed to read CSV row %d: %w", rowCount+1, err)
		}
		rowCount++
	}

	return rowCount, nil
}

// ValidateCSVStructure performs basic validation on CSV file structure
func ValidateCSVStructure(csvPath string) error {
	file, err := os.Open(csvPath)
	if err != nil {
		return fmt.Errorf("failed to open CSV file: %w", err)
	}
	defer file.Close()

	reader := csv.NewReader(file)
	reader.LazyQuotes = true
	reader.FieldsPerRecord = -1

	// Read first row (headers)
	headers, err := reader.Read()
	if err != nil {
		return fmt.Errorf("failed to read CSV headers: %w", err)
	}

	if len(headers) == 0 {
		return fmt.Errorf("CSV file has no columns")
	}

	// Check for duplicate headers
	headerMap := make(map[string]bool)
	for _, header := range headers {
		cleanHeader := strings.TrimSpace(header)
		if cleanHeader == "" {
			return fmt.Errorf("CSV file has empty column header")
		}
		if headerMap[cleanHeader] {
			return fmt.Errorf("CSV file has duplicate column header: %s", cleanHeader)
		}
		headerMap[cleanHeader] = true
	}

	return nil
}

// GetCSVColumnTypes analyzes a CSV file and returns inferred data types for each column
func GetCSVColumnTypes(csvPath string, sampleSize int) ([]string, []string, error) {
	headers, rows, err := GetCSVColumnsAndSampleRows(csvPath, sampleSize)
	if err != nil {
		return nil, nil, err
	}

	if len(rows) == 0 {
		// No data rows, default all to Text
		types := make([]string, len(headers))
		for i := range types {
			types[i] = "sc:Text"
		}
		return headers, types, nil
	}

	// Analyze each column
	columnTypes := make([]string, len(headers))
	for i := range headers {
		typeCounts := make(map[string]int)
		totalSamples := 0

		// Collect samples for this column
		for _, row := range rows {
			if i < len(row) && strings.TrimSpace(row[i]) != "" {
				dataType := InferDataType(row[i])
				typeCounts[dataType]++
				totalSamples++
			}
		}

		if totalSamples == 0 {
			columnTypes[i] = "sc:Text"
			continue
		}

		// Find the most common type
		maxCount := 0
		mostCommonType := "sc:Text"
		for dataType, count := range typeCounts {
			if count > maxCount {
				maxCount = count
				mostCommonType = dataType
			}
		}

		// If less than 70% of samples match the most common type, default to Text
		if float64(maxCount)/float64(totalSamples) < 0.7 {
			columnTypes[i] = "sc:Text"
		} else {
			columnTypes[i] = mostCommonType
		}
	}

	return headers, columnTypes, nil
}

// IsCSVFile checks if a file appears to be a CSV file based on extension
func IsCSVFile(filePath string) bool {
	ext := strings.ToLower(filepath.Ext(filePath))
	return ext == ".csv" || ext == ".tsv" || ext == ".txt"
}

// SanitizeFileName removes or replaces invalid characters in filenames
func SanitizeFileName(fileName string) string {
	// Replace invalid characters with underscores
	invalid := []string{"/", "\\", ":", "*", "?", "\"", "<", ">", "|"}
	result := fileName
	for _, char := range invalid {
		result = strings.ReplaceAll(result, char, "_")
	}
	return result
}

</pkg/croissant/utils.go>

<pkg/croissant/structs.go>
// structs.go
package croissant

// Field represents a field in the Croissant metadata
type Field struct {
	ID          string      `json:"@id"`
	Type        string      `json:"@type"`
	Name        string      `json:"name"`
	Description string      `json:"description,omitempty"`
	DataType    string      `json:"dataType"`
	Source      FieldSource `json:"source"`
	Repeated    bool        `json:"repeated,omitempty"`
	Examples    interface{} `json:"examples,omitempty"`
}

// FieldSource represents the source information for a field
type FieldSource struct {
	Extract    Extract    `json:"extract"`
	FileObject FileObject `json:"fileObject"`
}

// Extract represents the extraction information for a field source
type Extract struct {
	Column    string `json:"column,omitempty"`
	JSONPath  string `json:"jsonPath,omitempty"`
	Regex     string `json:"regex,omitempty"`
	Separator string `json:"separator,omitempty"`
}

// FileObject represents a file object reference
type FileObject struct {
	ID string `json:"@id"`
}

// Distribution represents a file in the Croissant metadata
type Distribution struct {
	ID             string `json:"@id"`
	Type           string `json:"@type"`
	Name           string `json:"name"`
	Description    string `json:"description,omitempty"`
	ContentSize    string `json:"contentSize,omitempty"`
	ContentURL     string `json:"contentUrl"`
	EncodingFormat string `json:"encodingFormat"`
	SHA256         string `json:"sha256,omitempty"`
	MD5            string `json:"md5,omitempty"`
}

// RecordSet represents a record set in the Croissant metadata
type RecordSet struct {
	ID          string  `json:"@id"`
	Type        string  `json:"@type"`
	Name        string  `json:"name"`
	Description string  `json:"description,omitempty"`
	Fields      []Field `json:"field"`
	Key         string  `json:"key,omitempty"`
}

// Context represents the complete JSON-LD context for Croissant 1.0
type Context struct {
	Language      string          `json:"@language"`
	Vocab         string          `json:"@vocab"`
	CiteAs        string          `json:"citeAs"`
	Column        string          `json:"column"`
	ConformsTo    string          `json:"conformsTo"`
	CR            string          `json:"cr"`
	DCT           string          `json:"dct"`
	RAI           string          `json:"rai,omitempty"`
	Data          DataContext     `json:"data"`
	DataType      DataTypeContext `json:"dataType"`
	Examples      DataContext     `json:"examples"`
	Extract       string          `json:"extract"`
	Field         string          `json:"field"`
	FileObject    string          `json:"fileObject"`
	FileProperty  string          `json:"fileProperty"`
	FileSet       string          `json:"fileSet"`
	Format        string          `json:"format"`
	Includes      string          `json:"includes"`
	IsLiveDataset string          `json:"isLiveDataset"`
	JSONPath      string          `json:"jsonPath"`
	Key           string          `json:"key"`
	MD5           string          `json:"md5"`
	ParentField   string          `json:"parentField"`
	Path          string          `json:"path"`
	RecordSet     string          `json:"recordSet"`
	References    string          `json:"references"`
	Regex         string          `json:"regex"`
	Repeated      string          `json:"repeated"`
	Replace       string          `json:"replace"`
	SC            string          `json:"sc"`
	Separator     string          `json:"separator"`
	Source        string          `json:"source"`
	SubField      string          `json:"subField"`
	Transform     string          `json:"transform"`
}

// DataContext represents the data field in the context
type DataContext struct {
	ID   string `json:"@id"`
	Type string `json:"@type"`
}

// DataTypeContext represents the dataType field in the context
type DataTypeContext struct {
	ID   string `json:"@id"`
	Type string `json:"@type"`
}

// Metadata represents the complete Croissant metadata
type Metadata struct {
	Context       Context        `json:"@context"`
	Type          string         `json:"@type"`
	Name          string         `json:"name"`
	Description   string         `json:"description,omitempty"`
	ConformsTo    string         `json:"conformsTo"`
	DatePublished string         `json:"datePublished,omitempty"`
	Version       string         `json:"version,omitempty"`
	URL           string         `json:"url,omitempty"`
	License       string         `json:"license,omitempty"`
	CiteAs        string         `json:"citeAs,omitempty"`
	Creator       interface{}    `json:"creator,omitempty"`
	Publisher     interface{}    `json:"publisher,omitempty"`
	Keywords      []string       `json:"keywords,omitempty"`
	Distributions []Distribution `json:"distribution"`
	RecordSets    []RecordSet    `json:"recordSet"`
	IsLiveDataset bool           `json:"isLiveDataset,omitempty"`
}

// Transform represents a data transformation
type Transform struct {
	Type      string `json:"@type"`
	Regex     string `json:"regex,omitempty"`
	Replace   string `json:"replace,omitempty"`
	Format    string `json:"format,omitempty"`
	JSONPath  string `json:"jsonPath,omitempty"`
	Separator string `json:"separator,omitempty"`
}

// Source represents a more complete source definition
type Source struct {
	Extract    Extract     `json:"extract,omitempty"`
	FileObject FileObject  `json:"fileObject,omitempty"`
	Field      string      `json:"field,omitempty"`
	Transform  []Transform `json:"transform,omitempty"`
}

</pkg/croissant/structs.go>

<pkg/croissant/node.go>
// node.go
package croissant

// Node represents a node in the Croissant metadata structure
type Node interface {
	GetName() string
	GetID() string
	GetParent() Node
	SetParent(Node)
	Validate(*Issues)
}

// BaseNode implements common functionality for all nodes
type BaseNode struct {
	ID     string `json:"@id,omitempty"`
	Name   string `json:"name,omitempty"`
	parent Node
}

func (n *BaseNode) GetName() string {
	return n.Name
}

func (n *BaseNode) GetID() string {
	return n.ID
}

func (n *BaseNode) GetParent() Node {
	return n.parent
}

func (n *BaseNode) SetParent(parent Node) {
	n.parent = parent
}

</pkg/croissant/node.go>

<pkg/croissant/metadata_node.go>
// metadata_node.go
package croissant

import "fmt"

// MetadataNode represents a Croissant metadata document
type MetadataNode struct {
	BaseNode
	Context       Context             `json:"@context"`
	Type          string              `json:"@type"`
	Description   string              `json:"description,omitempty"`
	ConformsTo    string              `json:"conformsTo,omitempty"`
	DatePublished string              `json:"datePublished,omitempty"`
	Version       string              `json:"version,omitempty"`
	Distributions []*DistributionNode `json:"distribution"`
	RecordSets    []*RecordSetNode    `json:"recordSet"`
	Issues        *Issues             `json:"-"` // Not serialized to JSON
}

// NewMetadataNode creates a new MetadataNode
func NewMetadataNode() *MetadataNode {
	return &MetadataNode{
		BaseNode: BaseNode{
			Name: "",
		},
		Context:       CreateDefaultContext(),
		Type:          "sc:Dataset",
		Distributions: make([]*DistributionNode, 0),
		RecordSets:    make([]*RecordSetNode, 0),
		Issues:        NewIssues(),
	}
}

// Validate validates the metadata node
func (m *MetadataNode) Validate(issues *Issues) {
	// Validate required fields
	if m.Name == "" {
		issues.AddError("Property \"https://schema.org/name\" is mandatory, but does not exist.", m)
	}

	// Validate type
	if m.Type != "sc:Dataset" {
		issues.AddError("The current JSON-LD doesn't extend https://schema.org/Dataset.", m)
	}

	// Validate distributions
	for _, dist := range m.Distributions {
		dist.SetParent(m)
		dist.Validate(issues)
	}

	// Validate record sets
	for _, rs := range m.RecordSets {
		rs.SetParent(m)
		rs.Validate(issues)
	}

	// Validate conformsTo is set
	if m.ConformsTo == "" {
		issues.AddWarning("Property \"http://purl.org/dc/terms/conformsTo\" is recommended, but does not exist.", m)
	}
}

// FromMetadata converts a Metadata struct to a MetadataNode
func FromMetadata(metadata Metadata) *MetadataNode {
	node := &MetadataNode{
		BaseNode: BaseNode{
			Name: metadata.Name,
		},
		Context:       metadata.Context,
		Type:          metadata.Type,
		Description:   metadata.Description,
		ConformsTo:    metadata.ConformsTo,
		DatePublished: metadata.DatePublished,
		Version:       metadata.Version,
		Issues:        NewIssues(),
	}

	// Convert distributions
	for _, dist := range metadata.Distributions {
		distNode := &DistributionNode{
			BaseNode: BaseNode{
				ID:   dist.ID,
				Name: dist.Name,
			},
			Type:           dist.Type,
			ContentSize:    dist.ContentSize,
			ContentURL:     dist.ContentURL,
			EncodingFormat: dist.EncodingFormat,
			SHA256:         dist.SHA256,
		}
		distNode.SetParent(node)
		node.Distributions = append(node.Distributions, distNode)
	}

	// Convert record sets
	for _, rs := range metadata.RecordSets {
		rsNode := &RecordSetNode{
			BaseNode: BaseNode{
				ID:   rs.ID,
				Name: rs.Name,
			},
			Type:        rs.Type,
			Description: rs.Description,
		}
		rsNode.SetParent(node)

		// Convert fields
		for _, field := range rs.Fields {
			fieldNode := &FieldNode{
				BaseNode: BaseNode{
					ID:   field.ID,
					Name: field.Name,
				},
				Type:        field.Type,
				Description: field.Description,
				DataType:    field.DataType,
				Source: SourceNode{
					Extract: ExtractNode{
						Column: field.Source.Extract.Column,
					},
					FileObject: FileObjectRef{
						ID: field.Source.FileObject.ID,
					},
				},
			}
			fieldNode.SetParent(rsNode)
			rsNode.Fields = append(rsNode.Fields, fieldNode)
		}

		node.RecordSets = append(node.RecordSets, rsNode)
	}

	return node
}

// DistributionNode represents a file distribution
type DistributionNode struct {
	BaseNode
	Type           string `json:"@type"`
	ContentSize    string `json:"contentSize,omitempty"`
	ContentURL     string `json:"contentUrl,omitempty"`
	EncodingFormat string `json:"encodingFormat,omitempty"`
	SHA256         string `json:"sha256,omitempty"`
	MD5            string `json:"md5,omitempty"`
}

// Validate validates the distribution node
func (d *DistributionNode) Validate(issues *Issues) {
	// Validate required fields
	if d.Name == "" {
		issues.AddError("Property \"https://schema.org/name\" is mandatory, but does not exist.", d)
	}

	// Validate type
	if d.Type != "cr:FileObject" && d.Type != "cr:FileSet" {
		issues.AddError(fmt.Sprintf("\"%s\" should have an attribute \"@type\": \"http://mlcommons.org/croissant/FileObject\" or \"@type\": \"http://mlcommons.org/croissant/FileSet\". Got %s instead.", d.Name, d.Type), d)
	}

	// Validate content URL
	if d.ContentURL == "" {
		issues.AddError("Property \"https://schema.org/contentUrl\" is mandatory, but does not exist.", d)
	}

	// Validate encoding format
	if d.EncodingFormat == "" {
		issues.AddError("Property \"https://schema.org/encodingFormat\" is mandatory, but does not exist.", d)
	}
}

// RecordSetNode represents a record set
type RecordSetNode struct {
	BaseNode
	Type        string       `json:"@type"`
	Description string       `json:"description,omitempty"`
	Fields      []*FieldNode `json:"field"`
}

// Validate validates the record set node
func (r *RecordSetNode) Validate(issues *Issues) {
	// Validate required fields
	if r.Name == "" {
		issues.AddError("Property \"https://schema.org/name\" is mandatory, but does not exist.", r)
	}

	// Validate type
	if r.Type != "cr:RecordSet" {
		issues.AddError(fmt.Sprintf("\"%s\" should have an attribute \"@type\": \"http://mlcommons.org/croissant/RecordSet\". Got %s instead.", r.Name, r.Type), r)
	}

	// Validate fields
	for _, field := range r.Fields {
		field.SetParent(r)
		field.Validate(issues)
	}
}

// FieldNode represents a field
type FieldNode struct {
	BaseNode
	Type        string     `json:"@type"`
	Description string     `json:"description,omitempty"`
	DataType    string     `json:"dataType,omitempty"`
	Source      SourceNode `json:"source"`
}

// Validate validates the field node
func (f *FieldNode) Validate(issues *Issues) {
	// Validate required fields
	if f.Name == "" {
		issues.AddError("Property \"https://schema.org/name\" is mandatory, but does not exist.", f)
	}

	// Validate type
	if f.Type != "cr:Field" {
		issues.AddError(fmt.Sprintf("\"%s\" should have an attribute \"@type\": \"http://mlcommons.org/croissant/Field\". Got %s instead.", f.Name, f.Type), f)
	}

	// Validate data type
	if f.DataType == "" {
		issues.AddError(fmt.Sprintf("The field does not specify a valid http://mlcommons.org/croissant/dataType, neither does any of its predecessor. Got: %s", f.DataType), f)
	}

	// Validate source
	if !f.Source.ValidateSource() {
		issues.AddError(fmt.Sprintf("Node \"%s\" is a field and has no source. Please, use http://mlcommons.org/croissant/source to specify the source.", f.ID), f)
	}
}

// SourceNode represents a source
type SourceNode struct {
	Extract    ExtractNode   `json:"extract"`
	FileObject FileObjectRef `json:"fileObject"`
}

// ValidateSource validates the source node
func (s *SourceNode) ValidateSource() bool {
	// Check if both extract and file object references are valid
	return s.Extract.Column != "" && s.FileObject.ID != ""
}

// ExtractNode represents extraction details
type ExtractNode struct {
	Column string `json:"column,omitempty"`
}

// FileObjectRef represents a reference to a file object
type FileObjectRef struct {
	ID string `json:"@id"`
}

</pkg/croissant/metadata_node.go>

<pkg/croissant/issues.go>
// issues.go
package croissant

import (
	"fmt"
	"sort"
	"strings"
)

// IssueType represents the type of issue (error or warning)
type IssueType int

const (
	ErrorIssue IssueType = iota
	WarningIssue
)

// Issue represents a single validation issue
type Issue struct {
	Type    IssueType
	Message string
	Context string // For context like "Metadata(mydataset) > FileObject(a-csv-table)"
}

// Issues represents a collection of validation issues
type Issues struct {
	errors   map[string]struct{}
	warnings map[string]struct{}
}

// NewIssues creates a new Issues instance
func NewIssues() *Issues {
	return &Issues{
		errors:   make(map[string]struct{}),
		warnings: make(map[string]struct{}),
	}
}

// AddError adds a new error to the issues collection
func (i *Issues) AddError(message string, node ...Node) {
	var context string
	if len(node) > 0 {
		context = getIssueContext(node[0])
		if context != "" {
			message = fmt.Sprintf("[%s] %s", context, message)
		}
	}
	i.errors[message] = struct{}{}
}

// AddWarning adds a new warning to the issues collection
func (i *Issues) AddWarning(message string, node ...Node) {
	var context string
	if len(node) > 0 {
		context = getIssueContext(node[0])
		if context != "" {
			message = fmt.Sprintf("[%s] %s", context, message)
		}
	}
	i.warnings[message] = struct{}{}
}

// HasErrors returns true if there are any errors
func (i *Issues) HasErrors() bool {
	return len(i.errors) > 0
}

// HasWarnings returns true if there are any warnings
func (i *Issues) HasWarnings() bool {
	return len(i.warnings) > 0
}

// ErrorCount returns the number of errors
func (i *Issues) ErrorCount() int {
	return len(i.errors)
}

// WarningCount returns the number of warnings
func (i *Issues) WarningCount() int {
	return len(i.warnings)
}

// Report generates a human-readable report of all issues
func (i *Issues) Report() string {
	var result strings.Builder

	// Sort before printing because maps are not ordered
	if len(i.errors) > 0 {
		errors := make([]string, 0, len(i.errors))
		for err := range i.errors {
			errors = append(errors, err)
		}
		sort.Strings(errors)

		result.WriteString(fmt.Sprintf("Found the following %d error(s) during the validation:\n", len(errors)))
		for _, err := range errors {
			result.WriteString(fmt.Sprintf("  -  %s\n", err))
		}
	}

	if len(i.warnings) > 0 {
		warnings := make([]string, 0, len(i.warnings))
		for warn := range i.warnings {
			warnings = append(warnings, warn)
		}
		sort.Strings(warnings)

		if result.Len() > 0 {
			result.WriteString("\n")
		}
		result.WriteString(fmt.Sprintf("Found the following %d warning(s) during the validation:\n", len(warnings)))
		for _, warn := range warnings {
			result.WriteString(fmt.Sprintf("  -  %s\n", warn))
		}
	}

	return strings.TrimSpace(result.String())
}

// getIssueContext generates a context string for an issue based on the node
func getIssueContext(node Node) string {
	if node == nil {
		return ""
	}

	// Build up context by traversing parent hierarchy
	var parts []string
	current := node

	for current != nil {
		nodeType := getNodeType(current)
		nodeName := current.GetName()
		if nodeName == "" {
			parts = append([]string{nodeType + "()"}, parts...)
		} else {
			parts = append([]string{nodeType + "(" + nodeName + ")"}, parts...)
		}
		current = current.GetParent()
	}

	return strings.Join(parts, " > ")
}

// getNodeType returns the type name of a node
func getNodeType(node Node) string {
	switch node.(type) {
	case *MetadataNode:
		return "Metadata"
	case *DistributionNode:
		return "FileObject"
	case *RecordSetNode:
		return "RecordSet"
	case *FieldNode:
		return "Field"
	default:
		return "Node"
	}
}

</pkg/croissant/issues.go>

<pkg/croissant/validation.go>
// validation.go
package croissant

import (
	"encoding/json"
	"fmt"
	"net/url"
	"os"
	"regexp"
	"strings"
)

// ValidationOptions represents options for validation
type ValidationOptions struct {
	StrictMode      bool
	CheckDataTypes  bool
	ValidateURLs    bool
	CheckFileExists bool
}

// DefaultValidationOptions returns default validation options
func DefaultValidationOptions() ValidationOptions {
	return ValidationOptions{
		StrictMode:      true,
		CheckDataTypes:  true,
		ValidateURLs:    false, // Don't validate URLs by default to avoid network calls
		CheckFileExists: false, // Don't check file existence by default
	}
}

// ValidateFile validates a Croissant metadata file and returns issues
func ValidateFile(filePath string) (*Issues, error) {
	data, err := os.ReadFile(filePath)
	if err != nil {
		return nil, fmt.Errorf("failed to read file: %w", err)
	}

	return ValidateJSON(data)
}

// ValidateJSON validates Croissant metadata in JSON format and returns issues
func ValidateJSON(data []byte) (*Issues, error) {
	var metadata Metadata
	if err := json.Unmarshal(data, &metadata); err != nil {
		return nil, fmt.Errorf("failed to parse JSON: %w", err)
	}

	return ValidateMetadata(metadata), nil
}

// ValidateJSONWithOptions validates Croissant metadata in JSON format with options and returns issues
func ValidateJSONWithOptions(data []byte, options ValidationOptions) (*Issues, error) {
	var metadata Metadata
	if err := json.Unmarshal(data, &metadata); err != nil {
		return nil, fmt.Errorf("failed to parse JSON: %w", err)
	}

	return ValidateMetadataWithOptions(metadata, options), nil
}

// ValidateMetadata validates a Metadata struct and returns issues
func ValidateMetadata(metadata Metadata) *Issues {
	return ValidateMetadataWithOptions(metadata, DefaultValidationOptions())
}

// ValidateMetadataWithOptions validates a Metadata struct with specific options
func ValidateMetadataWithOptions(metadata Metadata, options ValidationOptions) *Issues {
	node := FromMetadata(metadata)
	issues := NewIssues()

	// Run comprehensive validation
	ValidateMetadataNode(node, issues, options)

	return issues
}

// ValidateMetadataNode performs comprehensive validation of a metadata node
func ValidateMetadataNode(node *MetadataNode, issues *Issues, options ValidationOptions) {
	// Basic metadata validation
	if node.Name == "" {
		issues.AddError("Property \"https://schema.org/name\" is mandatory, but does not exist.", node)
	}

	if node.Type != "sc:Dataset" {
		issues.AddError("The current JSON-LD doesn't extend https://schema.org/Dataset.", node)
	}

	if node.ConformsTo == "" {
		issues.AddWarning("Property \"http://purl.org/dc/terms/conformsTo\" is recommended, but does not exist.", node)
	} else if !isValidConformsTo(node.ConformsTo) {
		issues.AddWarning(fmt.Sprintf("ConformsTo value \"%s\" is not a recognized Croissant version.", node.ConformsTo), node)
	}

	// Strict mode validations for metadata
	if options.StrictMode {
		if node.Description == "" {
			issues.AddWarning("Dataset description is recommended for better documentation.", node)
		}
		if node.Version == "" {
			issues.AddWarning("Dataset version is recommended for proper versioning.", node)
		}
		if node.DatePublished == "" {
			issues.AddWarning("Date published is recommended for dataset tracking.", node)
		}
	}

	// Validate distributions
	if len(node.Distributions) == 0 {
		issues.AddError("Dataset must have at least one distribution.", node)
	}

	for _, dist := range node.Distributions {
		dist.SetParent(node)
		ValidateDistributionNode(dist, issues, options)
	}

	// Validate record sets
	if len(node.RecordSets) == 0 {
		issues.AddError("Dataset must have at least one recordSet.", node)
	}

	for _, rs := range node.RecordSets {
		rs.SetParent(node)
		ValidateRecordSetNode(rs, issues, options)
	}

	// Cross-references validation
	ValidateCrossReferences(node, issues)
}

// ValidateDistributionNode validates a distribution node
func ValidateDistributionNode(dist *DistributionNode, issues *Issues, options ValidationOptions) {
	// Required fields validation
	if dist.Name == "" {
		issues.AddError("Property \"https://schema.org/name\" is mandatory, but does not exist.", dist)
	}

	if dist.Type != "cr:FileObject" && dist.Type != "cr:FileSet" {
		issues.AddError(fmt.Sprintf("\"%s\" should have an attribute \"@type\": \"http://mlcommons.org/croissant/FileObject\" or \"@type\": \"http://mlcommons.org/croissant/FileSet\". Got %s instead.", dist.Name, dist.Type), dist)
	}

	if dist.ContentURL == "" {
		issues.AddError("Property \"https://schema.org/contentUrl\" is mandatory, but does not exist.", dist)
	} else if options.ValidateURLs && !isValidURL(dist.ContentURL) {
		issues.AddError(fmt.Sprintf("ContentURL \"%s\" is not a valid URL.", dist.ContentURL), dist)
	}

	if dist.EncodingFormat == "" {
		issues.AddError("Property \"https://schema.org/encodingFormat\" is mandatory, but does not exist.", dist)
	} else if !isValidEncodingFormat(dist.EncodingFormat) {
		issues.AddWarning(fmt.Sprintf("EncodingFormat \"%s\" is not a recognized MIME type.", dist.EncodingFormat), dist)
	}

	// Hash validation
	if dist.SHA256 != "" && !isValidSHA256(dist.SHA256) {
		issues.AddError(fmt.Sprintf("SHA256 hash \"%s\" is not a valid SHA-256 hash.", dist.SHA256), dist)
	} else if options.StrictMode && dist.SHA256 == "" {
		issues.AddWarning("SHA256 hash is recommended for file integrity verification.", dist)
	}

	if dist.MD5 != "" && !isValidMD5(dist.MD5) {
		issues.AddError(fmt.Sprintf("MD5 hash \"%s\" is not a valid MD5 hash.", dist.MD5), dist)
	}

	// File existence check
	if options.CheckFileExists && isLocalFile(dist.ContentURL) {
		if _, err := os.Stat(dist.ContentURL); os.IsNotExist(err) {
			issues.AddWarning(fmt.Sprintf("File \"%s\" does not exist.", dist.ContentURL), dist)
		}
	}
}

// ValidateRecordSetNode validates a record set node
func ValidateRecordSetNode(rs *RecordSetNode, issues *Issues, options ValidationOptions) {
	if rs.Name == "" {
		issues.AddError("Property \"https://schema.org/name\" is mandatory, but does not exist.", rs)
	}

	if rs.Type != "cr:RecordSet" {
		issues.AddError(fmt.Sprintf("\"%s\" should have an attribute \"@type\": \"http://mlcommons.org/croissant/RecordSet\". Got %s instead.", rs.Name, rs.Type), rs)
	}

	if len(rs.Fields) == 0 {
		issues.AddWarning("RecordSet has no fields defined.", rs)
	}

	for _, field := range rs.Fields {
		field.SetParent(rs)
		ValidateFieldNode(field, issues, options)
	}
}

// ValidateFieldNode validates a field node
func ValidateFieldNode(field *FieldNode, issues *Issues, options ValidationOptions) {
	if field.Name == "" {
		issues.AddError("Property \"https://schema.org/name\" is mandatory, but does not exist.", field)
	}

	if field.Type != "cr:Field" {
		issues.AddError(fmt.Sprintf("\"%s\" should have an attribute \"@type\": \"http://mlcommons.org/croissant/Field\". Got %s instead.", field.Name, field.Type), field)
	}

	if field.DataType == "" {
		issues.AddError("The field does not specify a valid http://mlcommons.org/croissant/dataType, neither does any of its predecessor.", field)
	} else if options.CheckDataTypes && !isValidDataType(field.DataType) {
		issues.AddWarning(fmt.Sprintf("DataType \"%s\" is not a recognized schema.org type.", field.DataType), field)
	}

	// Strict mode validations for fields
	if options.StrictMode {
		if field.Description == "" {
			issues.AddWarning(fmt.Sprintf("Field \"%s\" is missing a description.", field.Name), field)
		}
	}

	if !field.Source.ValidateSource() {
		issues.AddError(fmt.Sprintf("Node \"%s\" is a field and has no source. Please, use http://mlcommons.org/croissant/source to specify the source.", field.ID), field)
	}
}

// ValidateCrossReferences validates that all references are valid
func ValidateCrossReferences(node *MetadataNode, issues *Issues) {
	// Build a map of all available IDs
	availableIDs := make(map[string]bool)

	// Add distribution IDs
	for _, dist := range node.Distributions {
		if dist.ID != "" {
			availableIDs[dist.ID] = true
		}
		if dist.Name != "" {
			availableIDs[dist.Name] = true
		}
	}

	// Add record set IDs
	for _, rs := range node.RecordSets {
		if rs.ID != "" {
			availableIDs[rs.ID] = true
		}
		if rs.Name != "" {
			availableIDs[rs.Name] = true
		}

		// Add field IDs
		for _, field := range rs.Fields {
			if field.ID != "" {
				availableIDs[field.ID] = true
			}
			fieldPath := fmt.Sprintf("%s/%s", rs.Name, field.Name)
			availableIDs[fieldPath] = true
		}
	}

	// Check field sources reference valid file objects
	for _, rs := range node.RecordSets {
		for _, field := range rs.Fields {
			if field.Source.FileObject.ID != "" {
				if !availableIDs[field.Source.FileObject.ID] {
					issues.AddError(fmt.Sprintf("Field \"%s\" references non-existent file object \"%s\".", field.Name, field.Source.FileObject.ID), field)
				}
			}
		}
	}
}

// AddValidationToMetadata adds validation functionality to the Metadata struct
type MetadataWithValidation struct {
	Metadata
	issues  *Issues
	options ValidationOptions
}

// NewMetadataWithValidation creates a new MetadataWithValidation instance
func NewMetadataWithValidation(metadata Metadata) *MetadataWithValidation {
	return &MetadataWithValidation{
		Metadata: metadata,
		options:  DefaultValidationOptions(),
	}
}

// Validate runs validation on the metadata
func (m *MetadataWithValidation) Validate() {
	m.issues = ValidateMetadataWithOptions(m.Metadata, m.options)
}

// ValidateWithOptions runs validation with specific options
func (m *MetadataWithValidation) ValidateWithOptions(options ValidationOptions) {
	m.options = options
	m.issues = ValidateMetadataWithOptions(m.Metadata, options)
}

// Report returns a string report of validation issues
func (m *MetadataWithValidation) Report() string {
	if m.issues == nil {
		m.Validate()
	}
	return m.issues.Report()
}

// HasErrors returns true if there are validation errors
func (m *MetadataWithValidation) HasErrors() bool {
	if m.issues == nil {
		m.Validate()
	}
	return m.issues.HasErrors()
}

// HasWarnings returns true if there are validation warnings
func (m *MetadataWithValidation) HasWarnings() bool {
	if m.issues == nil {
		m.Validate()
	}
	return m.issues.HasWarnings()
}

// GetIssues returns the validation issues
func (m *MetadataWithValidation) GetIssues() *Issues {
	if m.issues == nil {
		m.Validate()
	}
	return m.issues
}

// Validation helper functions

func isValidConformsTo(conformsTo string) bool {
	validVersions := []string{
		"http://mlcommons.org/croissant/1.0",
		"http://mlcommons.org/croissant/0.8",
	}
	for _, version := range validVersions {
		if conformsTo == version {
			return true
		}
	}
	return false
}

func isValidURL(urlStr string) bool {
	if urlStr == "" {
		return false
	}

	// Allow relative URLs and file paths
	if !strings.Contains(urlStr, "://") {
		return true
	}

	_, err := url.ParseRequestURI(urlStr)
	return err == nil
}

func isLocalFile(urlStr string) bool {
	return !strings.HasPrefix(urlStr, "http://") && !strings.HasPrefix(urlStr, "https://") && !strings.HasPrefix(urlStr, "ftp://")
}

func isValidEncodingFormat(format string) bool {
	// Common MIME types for datasets
	validFormats := map[string]bool{
		"text/csv":                  true,
		"application/json":          true,
		"application/jsonl":         true,
		"text/plain":                true,
		"application/xml":           true,
		"text/xml":                  true,
		"application/parquet":       true,
		"text/tab-separated-values": true,
		"application/zip":           true,
		"application/gzip":          true,
		"application/x-tar":         true,
		"image/jpeg":                true,
		"image/png":                 true,
		"image/tiff":                true,
		"audio/wav":                 true,
		"audio/mpeg":                true,
		"video/mp4":                 true,
		"application/pdf":           true,
	}

	return validFormats[format] || strings.HasPrefix(format, "text/") || strings.HasPrefix(format, "application/") || strings.HasPrefix(format, "image/") || strings.HasPrefix(format, "audio/") || strings.HasPrefix(format, "video/")
}

func isValidDataType(dataType string) bool {
	validTypes := map[string]bool{
		"sc:Text":     true,
		"sc:Integer":  true,
		"sc:Number":   true,
		"sc:Float":    true,
		"sc:Boolean":  true,
		"sc:Date":     true,
		"sc:DateTime": true,
		"sc:Time":     true,
		"sc:URL":      true,
	}

	return validTypes[dataType]
}

func isValidSHA256(hash string) bool {
	matched, _ := regexp.MatchString("^[a-fA-F0-9]{64}$", hash)
	return matched
}

func isValidMD5(hash string) bool {
	matched, _ := regexp.MatchString("^[a-fA-F0-9]{32}$", hash)
	return matched
}

</pkg/croissant/validation.go>

<pkg/croissant/croissant.go>
// croissant.go
package croissant

import (
	"encoding/json"
	"fmt"
	"net/url"
	"os"
	"path/filepath"
	"regexp"
	"strconv"
	"strings"
	"time"
)

// InferDataType infers the schema.org data type from a value
func InferDataType(value string) string {
	// Trim whitespace
	value = strings.TrimSpace(value)
	if value == "" {
		return "sc:Text"
	}

	// Try to parse as boolean
	lowerVal := strings.ToLower(value)
	if lowerVal == "true" || lowerVal == "false" {
		return "sc:Boolean"
	}

	// Try to parse as integer
	if _, err := strconv.ParseInt(value, 10, 64); err == nil {
		return "sc:Integer"
	}

	// Try to parse as float
	if _, err := strconv.ParseFloat(value, 64); err == nil {
		return "sc:Number"
	}

	// Try to parse as date (various formats)
	dateFormats := []string{
		"2006-01-02",
		"01/02/2006",
		"2006/01/02",
		"2006-01-02T15:04:05",
		"2006-01-02T15:04:05Z",
		"2006-01-02T15:04:05-07:00",
	}
	for _, format := range dateFormats {
		if _, err := time.Parse(format, value); err == nil {
			return "sc:DateTime"
		}
	}

	// Try to parse as URL
	if _, err := url.ParseRequestURI(value); err == nil && (strings.HasPrefix(value, "http://") || strings.HasPrefix(value, "https://")) {
		return "sc:URL"
	}

	// Try to detect email
	emailRegex := regexp.MustCompile(`^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$`)
	if emailRegex.MatchString(value) {
		return "sc:Text" // Email is still text but we could add a custom type if needed
	}

	// Default to Text
	return "sc:Text"
}

// CreateDefaultContext creates the ML Commons Croissant 1.0 compliant context
func CreateDefaultContext() Context {
	return Context{
		Language:   "en",
		Vocab:      "https://schema.org/",
		CiteAs:     "cr:citeAs",
		Column:     "cr:column",
		ConformsTo: "dct:conformsTo",
		CR:         "http://mlcommons.org/croissant/",
		DCT:        "http://purl.org/dc/terms/",
		RAI:        "http://mlcommons.org/croissant/RAI/",
		Data: DataContext{
			ID:   "cr:data",
			Type: "@json",
		},
		DataType: DataTypeContext{
			ID:   "cr:dataType",
			Type: "@vocab",
		},
		Examples: DataContext{
			ID:   "cr:examples",
			Type: "@json",
		},
		Extract:       "cr:extract",
		Field:         "cr:field",
		FileObject:    "cr:fileObject",
		FileProperty:  "cr:fileProperty",
		FileSet:       "cr:fileSet",
		Format:        "cr:format",
		Includes:      "cr:includes",
		IsLiveDataset: "cr:isLiveDataset",
		JSONPath:      "cr:jsonPath",
		Key:           "cr:key",
		MD5:           "cr:md5",
		ParentField:   "cr:parentField",
		Path:          "cr:path",
		RecordSet:     "cr:recordSet",
		References:    "cr:references",
		Regex:         "cr:regex",
		Repeated:      "cr:repeated",
		Replace:       "cr:replace",
		SC:            "https://schema.org/",
		Separator:     "cr:separator",
		Source:        "cr:source",
		SubField:      "cr:subField",
		Transform:     "cr:transform",
	}
}

// GenerateMetadata generates Croissant metadata from a CSV file (simple API)
func GenerateMetadata(csvPath string, outputPath string) (string, error) {
	metadata, err := GenerateMetadataWithValidation(csvPath, outputPath)
	if err != nil {
		return "", err
	}

	// Check if there are validation errors
	if metadata.HasErrors() {
		return "", fmt.Errorf("validation failed: %s", metadata.Report())
	}

	return outputPath, nil
}

// GenerateMetadataWithValidation generates Croissant metadata with validation from a CSV file
func GenerateMetadataWithValidation(csvPath string, outputPath string) (*MetadataWithValidation, error) {
	// Get file information
	fileName := filepath.Base(csvPath)
	fileInfo, err := os.Stat(csvPath)
	if err != nil {
		return nil, fmt.Errorf("failed to get file info: %w", err)
	}
	fileSize := fileInfo.Size()

	// Calculate SHA-256 hash
	fileSHA256, err := CalculateSHA256(csvPath)
	if err != nil {
		return nil, fmt.Errorf("failed to calculate SHA-256: %w", err)
	}

	// Get column information
	headers, firstRow, err := GetCSVColumns(csvPath)
	if err != nil {
		return nil, fmt.Errorf("failed to read CSV: %w", err)
	}

	// Create fields based on CSV columns with data type inference
	fields := make([]Field, 0, len(headers))
	for i, header := range headers {
		fieldID := fmt.Sprintf("main/%s", cleanFieldName(header))
		dataType := "sc:Text" // Default

		// Infer data type from first row if available
		if firstRow != nil && i < len(firstRow) {
			dataType = InferDataType(firstRow[i])
		}

		field := Field{
			ID:          fieldID,
			Type:        "cr:Field",
			Name:        header,
			Description: fmt.Sprintf("Field for %s", header),
			DataType:    dataType,
			Source: FieldSource{
				Extract: Extract{
					Column: header,
				},
				FileObject: FileObject{
					ID: fileName,
				},
			},
		}

		fields = append(fields, field)
	}

	// Create metadata structure
	datasetName := strings.TrimSuffix(fileName, filepath.Ext(fileName))
	metadata := Metadata{
		Context:       CreateDefaultContext(),
		Type:          "sc:Dataset",
		Name:          fmt.Sprintf("%s_dataset", datasetName),
		Description:   fmt.Sprintf("Dataset created from %s", fileName),
		ConformsTo:    "http://mlcommons.org/croissant/1.0",
		DatePublished: time.Now().Format("2006-01-02"),
		Version:       "1.0.0",
		Distributions: []Distribution{
			{
				ID:             fileName,
				Type:           "cr:FileObject",
				Name:           fileName,
				ContentSize:    fmt.Sprintf("%d B", fileSize),
				ContentURL:     fileName,
				EncodingFormat: "text/csv",
				SHA256:         fileSHA256,
			},
		},
		RecordSets: []RecordSet{
			{
				ID:          "main",
				Type:        "cr:RecordSet",
				Name:        "main",
				Description: fmt.Sprintf("Records from %s", fileName),
				Fields:      fields,
			},
		},
	}

	// Write to file if output path is provided
	if outputPath != "" {
		// Marshal metadata to JSON with proper indentation
		metadataJSON, err := json.MarshalIndent(metadata, "", "  ")
		if err != nil {
			return nil, fmt.Errorf("failed to marshal JSON: %w", err)
		}

		// Ensure directory exists
		if err := os.MkdirAll(filepath.Dir(outputPath), 0755); err != nil {
			return nil, fmt.Errorf("failed to create output directory: %w", err)
		}

		// Write metadata to file
		if err := os.WriteFile(outputPath, metadataJSON, 0644); err != nil {
			return nil, fmt.Errorf("failed to write file: %w", err)
		}
	}

	// Create and validate metadata
	metadataWithValidation := &MetadataWithValidation{
		Metadata: metadata,
	}
	metadataWithValidation.Validate()

	return metadataWithValidation, nil
}

// cleanFieldName cleans field names to be valid identifiers
func cleanFieldName(name string) string {
	// Replace spaces and special characters with underscores
	reg := regexp.MustCompile(`[^a-zA-Z0-9_]`)
	cleaned := reg.ReplaceAllString(name, "_")

	// Remove leading/trailing underscores and multiple consecutive underscores
	cleaned = strings.Trim(cleaned, "_")
	reg2 := regexp.MustCompile(`_{2,}`)
	cleaned = reg2.ReplaceAllString(cleaned, "_")

	// Ensure it doesn't start with a number
	if len(cleaned) > 0 && cleaned[0] >= '0' && cleaned[0] <= '9' {
		cleaned = "field_" + cleaned
	}

	return cleaned
}

// inferDataTypeFromSamples infers data type from multiple sample rows for better accuracy
func inferDataTypeFromSamples(columnIndex int, rows [][]string) string {
	if len(rows) == 0 {
		return "sc:Text"
	}

	typeCounts := make(map[string]int)
	totalSamples := 0

	for _, row := range rows {
		if columnIndex < len(row) && strings.TrimSpace(row[columnIndex]) != "" {
			dataType := InferDataType(row[columnIndex])
			typeCounts[dataType]++
			totalSamples++
		}
	}

	if totalSamples == 0 {
		return "sc:Text"
	}

	// Find the most common type
	maxCount := 0
	mostCommonType := "sc:Text"
	for dataType, count := range typeCounts {
		if count > maxCount {
			maxCount = count
			mostCommonType = dataType
		}
	}

	// If less than 80% of samples match the most common type, default to Text
	if float64(maxCount)/float64(totalSamples) < 0.8 {
		return "sc:Text"
	}

	return mostCommonType
}

</pkg/croissant/croissant.go>

<pkg/version/version.go>
package version

// These variables should be set at compile time
var (
	// AppName is the name of the application
	AppName = "gocroissant"

	// Version is the service version
	Version = "dev"

	// GitHash is the hash of git commit the service is built from
	GitHash = "dev"

	// BuildTime build time in RFC3339 format
	BuildTime = "now"
)

</pkg/version/version.go>

<README.md>
# gocroissant

[![Version](https://img.shields.io/badge/version-v0.1.1-blue)](https://github.com/beyondcivic/gocroissant/releases/tag/v0.1.1)
[![Go Version](https://img.shields.io/badge/Go-1.24+-00ADD8?logo=go)](https://golang.org/doc/devel/release.html)
[![License](https://img.shields.io/badge/license-TBD-red)](LICENSE)

A Go implementation for working with the [ML Commons Croissant](https://github.com/mlcommons/croissant) metadata format - a standardized way to describe machine learning datasets using JSON-LD.

## Overview

Croissant is an open metadata standard designed to improve dataset documentation, searchability, and usage in machine learning workflows. This library simplifies the creation of Croissant-compatible metadata from CSV data sources by:

- Automatically inferring schema types from dataset content
- Generating complete, valid JSON-LD metadata
- Providing validation tools to ensure compatibility
- Supporting the full Croissant specification

This project provides both a command-line interface and a Go library for converting CSV files to Croissant metadata format.

## Getting Started

### Prerequisites

- Go 1.24 or later
- Nix 2.25.4 or later
- Powershell v7.5.1 or later

### Installation

1. Clone the repository:

```bash
   git clone https://github.com/beyondcivic/gocroissant.git
   cd gocroissant
```

2. Prepare the environment using NIX flakes (optional but recommended):

```bash
nix develop
```

3. Build the application (NOTE: requires powershell v7.5.1):

```bash
./build.ps1
```

### Usage

#### Command Line Interface

```bash
# Generate metadata with default output path
./gocroissant data.csv

# Specify output path
./gocroissant data.csv -o output.json
```

#### Using the Library in Your Go Code

```go
package main

import (
	"fmt"
	"log"

	"github.com/beyondcivic/gocroissant/pkg/croissant"
)

func main() {
	outputPath, err := croissant.GenerateMetadata("data.csv", "dataset.jsonld")
	if err != nil {
		log.Fatalf("Error generating metadata: %v", err)
	}
	fmt.Printf("Metadata saved to: %s\n", outputPath)
}
```

## Features

- Automatically infers field data types from CSV content
- Calculates SHA-256 hash for file verification
- Generates Croissant metadata in JSON-LD format
- Configurable output path

## Configuration

The application supports configuration through environment variables with the prefix `CROISSANT_`.

NOTE: Currently, only `CROISSANT_OUTPUT_PATH` is supported to specify the output file path for generated metadata.

NOTE: If no output path is provided explicitly, the default output path `metadata.jsonld` will be used.

## Usage Examples

### Generate metadata without validation

```bash
$ gocroissant generate data.csv -o metadata.jsonld
```

### Generate metadata with validation

```bash
$ gocroissant generate data.csv -o metadata.jsonld -v

Validation passed with no issues.
Croissant metadata generated and saved to: metadata.json
```

### Generate metadata with validation but without saving to a file

```bash
$ gocroissant generate data.csv -v
Validation passed with no issues.
```

### Validate an existing metadata file

```bash
$ gocroissant validate metadata.json
Validation passed with no issues.
```

### Example with issues

```
$ gocroissant validate ./samples_jsonld/missing_fields.jsonld

Found the following 3 error(s) during the validation:
  -  [Metadata(mydataset) > FileObject(a-csv-table)] Property "https://schema.org/contentUrl" is mandatory, but does not exist.
  -  [Metadata(mydataset) > RecordSet(a-record-set) > Field(first-field)] The field does not specify a valid http://mlcommons.org/croissant/dataType, neither does any of its predecessor. Got:
  -  [Metadata(mydataset)] The current JSON-LD doesn't extend https://schema.org/Dataset.

Found the following 1 warning(s) during the validation:
  -  [Metadata(mydataset)] Property "http://purl.org/dc/terms/conformsTo" is recommended, but does not exist.
exit status 1
```

```bash
$ gocroissant validate ./samples_jsonld/invalid_references.jsonld

Found the following 1 error(s) during the validation:
  -  [Metadata(mydataset) > FileObject(a-csv-table)] "a-csv-table" should have an attribute "@type": "http://mlcommons.org/croissant/FileObject" or "@type": "http://mlcommons.org/croissant/FileSet". Got sc:WRONG_TYPE instead.
exit status 1
```

## Development

### Adding New Data Types

To add support for new data types, modify the `InferDataType` function in `croissant/croissant.go`:

```go
func InferDataType(value string) string {
	// Existing data type detection...

	// Add your new data type detection here
	if myCustomTypeDetector(value) {
		return "sc:MyCustomType"
	}

	// Default to Text
	return "sc:Text"
}
```

## License

TODO.

## Build environment

Use NIX flakes to setup the build environment.

```bash
nix develop
```

Check the build arguments in build.ps1, e.g.:

```bash
# Build static binary with version information
$env:CGO_ENABLED = "1"
$env:GOOS = "linux"
$env:GOARCH = "amd64"
```

Then run the following command to build the project:

```bash
./build.ps1
```

</README.md>

<build.ps1>
#!/usr/bin/env pwsh

# Set environment variables for static build
$env:CGO_ENABLED = "1"
$env:GOOS = "linux"
$APP_VERSION = "$(git describe --tags --abbrev=0 2>/dev/null || echo '0.0.0')"
$GIT_HASH = $(git log -1 --format='%H')
$BUILD_TIME = $(Get-Date -UFormat '%Y-%m-%dT%H:%M:%SZ')

# Create out directory if it doesn't exist
New-Item -ItemType Directory -Force -Path "bin"

# Build static binary with version information
$env:CGO_ENABLED = "1"
$env:GOOS = "linux"
$env:GOARCH = "amd64"

go build -v `
    -ldflags "-X 'github.com/beyondcivic/gocroissant/pkg/version.Version=$APP_VERSION' -X 'github.com/beyondcivic/gocroissant/pkg/version.GitHash=$GIT_HASH' -X 'github.com/beyondcivic/gocroissant/pkg/version.BuildTime=$BUILD_TIME'" `
    -o ./bin/gocroissant ./cmd/gocroissant

</build.ps1>

